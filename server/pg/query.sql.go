// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: query.sql

package pg

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const cleanupPendingClosures = `-- name: CleanupPendingClosures :execrows
WITH cutoff_time AS (
    SELECT timezone('UTC', now()) - interval '1 second' * $1::int AS time
),

old_closures AS (
    SELECT id
    FROM pending_closures, cutoff_time
    WHERE started_at < cutoff_time.time
),

inserted_objects AS (
    INSERT INTO objects (key, refs, deleted_at, first_deleted_at)
    SELECT
        po.key,
        po.refs,
        cutoff_time.time,
        cutoff_time.time
    FROM pending_objects AS po
    JOIN old_closures oc ON po.pending_closure_id = oc.id, cutoff_time
    ON CONFLICT (key) DO NOTHING
    RETURNING key
),

deleted_pending_objects AS (
    DELETE FROM pending_objects
    USING old_closures
    WHERE pending_objects.pending_closure_id = old_closures.id
    RETURNING pending_closure_id
)

DELETE FROM pending_closures
USING old_closures
WHERE pending_closures.id = old_closures.id
`

// Insert pending objects into objects table if they don't already exist
// We mark them as deleted so they can be cleaned up later
// Delete pending objects that were inserted into the objects table
// Delete pending closures older than the specified interval
// This will cascade to pending_objects
func (q *Queries) CleanupPendingClosures(ctx context.Context, dollar_1 int32) (int64, error) {
	result, err := q.db.Exec(ctx, cleanupPendingClosures, dollar_1)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected(), nil
}

const commitPendingClosure = `-- name: CommitPendingClosure :exec
SELECT commit_pending_closure($1::bigint)
`

func (q *Queries) CommitPendingClosure(ctx context.Context, dollar_1 int64) error {
	_, err := q.db.Exec(ctx, commitPendingClosure, dollar_1)
	return err
}

const deleteClosures = `-- name: DeleteClosures :execrows
DELETE FROM closures
WHERE updated_at < $1
`

func (q *Queries) DeleteClosures(ctx context.Context, updatedAt pgtype.Timestamp) (int64, error) {
	result, err := q.db.Exec(ctx, deleteClosures, updatedAt)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected(), nil
}

const deleteMultipartUpload = `-- name: DeleteMultipartUpload :exec
DELETE FROM multipart_uploads
WHERE upload_id = $1
`

func (q *Queries) DeleteMultipartUpload(ctx context.Context, uploadID string) error {
	_, err := q.db.Exec(ctx, deleteMultipartUpload, uploadID)
	return err
}

const deleteObjects = `-- name: DeleteObjects :exec
DELETE FROM objects
WHERE key = any($1::varchar [])
`

func (q *Queries) DeleteObjects(ctx context.Context, dollar_1 []string) error {
	_, err := q.db.Exec(ctx, deleteObjects, dollar_1)
	return err
}

const getClosure = `-- name: GetClosure :one
SELECT updated_at FROM closures
WHERE key = $1 LIMIT 1
`

func (q *Queries) GetClosure(ctx context.Context, key string) (pgtype.Timestamp, error) {
	row := q.db.QueryRow(ctx, getClosure, key)
	var updated_at pgtype.Timestamp
	err := row.Scan(&updated_at)
	return updated_at, err
}

const getClosureObjects = `-- name: GetClosureObjects :many
WITH RECURSIVE closure_reach AS (
    -- Start with the provided closure key
    SELECT o.key, o.refs 
    FROM objects o
    WHERE o.key = $1
    UNION
    -- Recursively add all referenced objects
    SELECT o.key, o.refs 
    FROM objects o
    INNER JOIN closure_reach cr ON o.key = ANY(cr.refs)
)
SELECT DISTINCT key FROM closure_reach
`

// Return objects reachable from the given closure key
func (q *Queries) GetClosureObjects(ctx context.Context, key string) ([]string, error) {
	rows, err := q.db.Query(ctx, getClosureObjects, key)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var key string
		if err := rows.Scan(&key); err != nil {
			return nil, err
		}
		items = append(items, key)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getExistingObjects = `-- name: GetExistingObjects :many
WITH ct AS (
    SELECT timezone('UTC', now()) AS now
)

SELECT
    o.key AS key,
    (CASE
        WHEN o.first_deleted_at IS NULL THEN NULL
        ELSE ct.now - o.first_deleted_at
    END)::interval AS deleted_at
FROM objects AS o, ct
WHERE key = any($1::varchar [])
`

type GetExistingObjectsRow struct {
	Key       string          `json:"key"`
	DeletedAt pgtype.Interval `json:"deleted_at"`
}

func (q *Queries) GetExistingObjects(ctx context.Context, dollar_1 []string) ([]GetExistingObjectsRow, error) {
	rows, err := q.db.Query(ctx, getExistingObjects, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetExistingObjectsRow
	for rows.Next() {
		var i GetExistingObjectsRow
		if err := rows.Scan(&i.Key, &i.DeletedAt); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getObjectsReadyForDeletion = `-- name: GetObjectsReadyForDeletion :many
SELECT key
FROM objects
WHERE first_deleted_at IS NOT NULL
  AND first_deleted_at <= timezone('UTC', now()) - interval '1 second' * $1::int
LIMIT $2
`

type GetObjectsReadyForDeletionParams struct {
	GracePeriodSeconds int32 `json:"grace_period_seconds"`
	LimitCount         int32 `json:"limit_count"`
}

// Returns objects marked for >= grace_period, safe to delete from S3
func (q *Queries) GetObjectsReadyForDeletion(ctx context.Context, arg GetObjectsReadyForDeletionParams) ([]string, error) {
	rows, err := q.db.Query(ctx, getObjectsReadyForDeletion, arg.GracePeriodSeconds, arg.LimitCount)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var key string
		if err := rows.Scan(&key); err != nil {
			return nil, err
		}
		items = append(items, key)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getOldMultipartUploads = `-- name: GetOldMultipartUploads :many
SELECT upload_id, object_key
FROM multipart_uploads mu
JOIN pending_closures pc ON mu.pending_closure_id = pc.id
WHERE pc.started_at < timezone('UTC', now()) - interval '1 second' * $1::int
`

type GetOldMultipartUploadsRow struct {
	UploadID  string `json:"upload_id"`
	ObjectKey string `json:"object_key"`
}

func (q *Queries) GetOldMultipartUploads(ctx context.Context, dollar_1 int32) ([]GetOldMultipartUploadsRow, error) {
	rows, err := q.db.Query(ctx, getOldMultipartUploads, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetOldMultipartUploadsRow
	for rows.Next() {
		var i GetOldMultipartUploadsRow
		if err := rows.Scan(&i.UploadID, &i.ObjectKey); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPendingObjectKeys = `-- name: GetPendingObjectKeys :many
SELECT key FROM pending_objects
WHERE pending_closure_id = $1
`

func (q *Queries) GetPendingObjectKeys(ctx context.Context, pendingClosureID int64) ([]string, error) {
	rows, err := q.db.Query(ctx, getPendingObjectKeys, pendingClosureID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var key string
		if err := rows.Scan(&key); err != nil {
			return nil, err
		}
		items = append(items, key)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const insertMultipartUpload = `-- name: InsertMultipartUpload :exec
INSERT INTO multipart_uploads (pending_closure_id, object_key, upload_id)
VALUES ($1, $2, $3)
`

type InsertMultipartUploadParams struct {
	PendingClosureID int64  `json:"pending_closure_id"`
	ObjectKey        string `json:"object_key"`
	UploadID         string `json:"upload_id"`
}

func (q *Queries) InsertMultipartUpload(ctx context.Context, arg InsertMultipartUploadParams) error {
	_, err := q.db.Exec(ctx, insertMultipartUpload, arg.PendingClosureID, arg.ObjectKey, arg.UploadID)
	return err
}

const insertPendingClosure = `-- name: InsertPendingClosure :one
INSERT INTO pending_closures (started_at, key)
VALUES (timezone('UTC', now()), $1)
RETURNING id, key, started_at
`

func (q *Queries) InsertPendingClosure(ctx context.Context, key string) (PendingClosure, error) {
	row := q.db.QueryRow(ctx, insertPendingClosure, key)
	var i PendingClosure
	err := row.Scan(&i.ID, &i.Key, &i.StartedAt)
	return i, err
}

type InsertPendingObjectsParams struct {
	PendingClosureID int64    `json:"pending_closure_id"`
	Key              string   `json:"key"`
	Refs             []string `json:"refs"`
}

const markObjectsAsActive = `-- name: MarkObjectsAsActive :exec
UPDATE objects SET deleted_at = NULL
WHERE key = any($1::varchar [])
`

func (q *Queries) MarkObjectsAsActive(ctx context.Context, dollar_1 []string) error {
	_, err := q.db.Exec(ctx, markObjectsAsActive, dollar_1)
	return err
}

const markStaleObjects = `-- name: MarkStaleObjects :execrows
WITH RECURSIVE ct AS (
    SELECT timezone('UTC', now()) AS now
),
closure_reach AS (
    -- Start with all closure keys
    SELECT o.key, o.refs
    FROM objects o
    INNER JOIN closures c ON o.key = c.key
    UNION
    -- Recursively add all referenced objects
    SELECT o.key, o.refs
    FROM objects o
    INNER JOIN closure_reach cr ON o.key = ANY(cr.refs)
),
reachable_objects AS (
    SELECT DISTINCT key FROM closure_reach
),
stale_objects AS (
    SELECT o.key
    FROM objects AS o, ct
    WHERE
        NOT EXISTS (
            SELECT 1
            FROM reachable_objects ro
            WHERE ro.key = o.key
        )
        AND NOT EXISTS (
            SELECT 1
            FROM pending_objects AS po
            WHERE po.key = o.key
        )
        AND o.deleted_at IS NULL  -- Only mark fresh objects
    FOR UPDATE
    LIMIT $1
)
UPDATE objects
SET
    deleted_at = ct.now,
    first_deleted_at = COALESCE(first_deleted_at, ct.now)
FROM stale_objects, ct
WHERE objects.key = stale_objects.key
`

// Find all objects reachable from any closure
func (q *Queries) MarkStaleObjects(ctx context.Context, limit int32) (int64, error) {
	result, err := q.db.Exec(ctx, markStaleObjects, limit)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected(), nil
}
